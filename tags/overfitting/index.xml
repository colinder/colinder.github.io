<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Overfitting - Tag - </title>
        <link>https://colinder.github.io/tags/overfitting/</link>
        <description>Overfitting - Tag - </description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 28 Dec 2022 16:44:00 &#43;0900</lastBuildDate><atom:link href="https://colinder.github.io/tags/overfitting/" rel="self" type="application/rss+xml" /><item>
    <title>Overfitting</title>
    <link>https://colinder.github.io/overfitting/</link>
    <pubDate>Wed, 28 Dec 2022 16:44:00 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://colinder.github.io/overfitting/</guid>
    <description><![CDATA[​
과적합(Overfitting)  잘 정리된 내용을 발견하였고 거기에 개인적인 경험을 추가하기 위해 정리하였습니다. (대부분 필사입니다.)
인공지능 모델링을 하다보면 항상 만나게 되는 과적합을 어떻게 해결해야하는지, 방법에 대하여 정리
 ​
인공지능에게 흔히 말하는 깊이있는 공부를 시키려면 모델의 layer을 늘리고, 노드(unit)을 늘리는 방법을 떠올린다. 그리고 그러다 보면 train data에 만 너무 적합하게, 처음 보는 test data를 집어넣었을 땐 형편없는 결과를 도출하는 모델이 된다. (이를 과적합이라 한다.)
일반적으로 과적합은 모델 학습과정에서 valid loss가 지속적으로 감소하다가 증가하는 지점부터 발생한다고 정의된다.]]></description>
</item></channel>
</rss>
