<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>AI - Category - </title>
        <link>https://colinder.github.io/categories/ai/</link>
        <description>AI - Category - </description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 30 Jun 2022 13:30:53 &#43;0900</lastBuildDate><atom:link href="https://colinder.github.io/categories/ai/" rel="self" type="application/rss+xml" /><item>
    <title>What is train_test_split()?</title>
    <link>https://colinder.github.io/what_is_train_test_split/</link>
    <pubDate>Thu, 30 Jun 2022 13:30:53 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://colinder.github.io/what_is_train_test_split/</guid>
    <description><![CDATA[â€‹
What is &lsquo;train_test_split()&rsquo;?  AI ëª¨ë¸ë§ì„ ìœ„í•´ X_train, X_test, y_train, y_testë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì€ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì €ëŠ” trainê³¼ testë¥¼ ë‚˜ëˆ„ëŠ” ì½”ë“œë¥¼ ì§ì ‘ ì§œì„œ ì‚¬ìš©í–ˆì—ˆëŠ”ë° scikit learnì—ì„œ ì œê³µë˜ëŠ” í•¨ìˆ˜ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. &ldquo;train_test_split()&quot;ì´ë¥¼ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.
 â€‹
â€‹
ì§ì ‘ ì‚¬ìš©ë˜ëŠ” ëª¨ìŠµì„ ë³´ë©° ì´í•´í•´ë³´ê² ìŠµë‹ˆë‹¤.
1 2 3 4  import numpy as np from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=29)   â€‹
â€‹
train_test_split() í•¨ìˆ˜ì•ˆì— ì‚¬ìš©ë˜ëŠ” ì¸ìì— ëŒ€í•˜ì—¬ í•˜ë‚˜ì”© ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.]]></description>
</item><item>
    <title>what is optimizer</title>
    <link>https://colinder.github.io/what_is_optimizer/</link>
    <pubDate>Fri, 18 Mar 2022 14:13:56 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://colinder.github.io/what_is_optimizer/</guid>
    <description><![CDATA[â€‹
â€‹
â€‹
ì˜µí‹°ë§ˆì´ì €ì˜ ëª©ì   ì˜µí‹°ë§ˆì´ì €ëŠ” í•™ìŠµ ë°ì´í„°(Train data)ì…‹ì„ ì´ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµ í•  ë•Œ ë°ì´í„°ì˜ ì‹¤ì œ ê²°ê³¼ì™€ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜¤ì°¨ë¥¼ ì˜ ì¤„ì¼ ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ì—­í• ì…ë‹ˆë‹¤.
 â€‹
ë”°ë¼ì„œ ìµœì í™”(Optimization)ì€ ì†ì‹¤ í•¨ìˆ˜(Loss Function)ì˜ ê²°ê³¼ê°’ì„ ìµœì†Œí™”í•˜ëŠ” ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜)ë¥¼ ì°¾ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
â€‹
â€‹
â€‹
ì˜µí‹°ë§ˆì´ì € ë¦¬ìŠ¤íŠ¸  ê²½ì‚¬ í•˜ê°•ë²•(Gradient Descent) í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(Stochastic Gradient Descent, SGD) Momentum Nesterov Accelerated Gradient (NAG) Adam AdaGrad RMSProp AdaMax Nadam  ì°¸ê³  https://keras.]]></description>
</item><item>
    <title>ëª¨ë¸ í•™ìŠµ ì‹œ lossê°€ Nanìœ¼ë¡œ ë‚˜ì˜¬ ë•Œ í•´ê²°ë²•</title>
    <link>https://colinder.github.io/loss_nan_solution/</link>
    <pubDate>Thu, 17 Mar 2022 17:12:00 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://colinder.github.io/loss_nan_solution/</guid>
    <description><![CDATA[â€‹
ëª¨ë¸ í•™ìŠµ ì‹œ loss ê°’ì´ Nanìœ¼ë¡œ ë‚˜ì˜¬ ë•Œ í•´ê²° ë°©ë²•   if df == pandas.DataFrame() df.isnull().any()ë¡œ ë°ì´í„°ì…‹ì— NaNì´ë‚˜ inf ê°’ì´ ë“¤ì–´ìˆëŠ”ì§€ í™•ì¸í•œë‹¤.
  ë‹¤ë¥¸ optimizerë“¤ì„ ì‚¬ìš©í•´ë³¸ë‹¤. (ex. sgd, adam, nadam)
  ë‹¤ë¥¸ activation functionì„ ì‚¬ìš©í•´ë³¸ë‹¤.
 ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ë§ˆë‹¤ ì í•©í•œ activation functionì´ ìˆìŠµë‹ˆë‹¤. ì¦‰. ëª¨ë¸ì— ëŒ€í•˜ì—¬ ê³µë¶€í•´ì•¼í•˜ê³ , ì í•©í•œ activation functionì„ ì°¾ì•„ í•™ìŠµí•´ì•¼ í•©ë‹ˆë‹¤.    learning rate(í•™ìŠµë¥ )ì„ ë‚®ì¶°ë³¸ë‹¤.
  learnin rateëŠ” batch_sizeì™€ ì—°ê´€ì´ ìˆìŠµë‹ˆë‹¤.
  ëŸ¬ë‹ë ˆì´íŠ¸ ì¤„ì´ê¸° vs ë°°ì¹˜ì‚¬ì´ì¦ˆ í‚¤ìš°ê¸°]]></description>
</item><item>
    <title>í¸í–¥(Bias) &amp; ë¶„ì‚°(Variance)</title>
    <link>https://colinder.github.io/biasvariance/</link>
    <pubDate>Mon, 14 Mar 2022 16:34:16 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://colinder.github.io/biasvariance/</guid>
    <description><![CDATA[â€‹
í¸í–¥(Bias)ê³¼ ë¶„ì‚°(Variance)  ì¸ê³µì§€ëŠ¥ ëª¨ë¸ë§ì„ í•˜ë©´ ì •ë‹µì„ ë§ì¶”ê¸° ìœ„í•´ ì»´í“¨í„°ëŠ” ì—¬ëŸ¬ ë²ˆì˜ ì˜ˆì¸¡ê°’ì„ ë‚´ë†“ëŠ”ë°, ì»´í“¨í„°ê°€ ë‚´ë†“ì€ ì˜ˆì¸¡ê°’ì˜ ë™íƒœë¥¼ ë¬˜ì‚¬í•˜ëŠ” í‘œí˜„ì´ &lsquo;í¸í–¥&rsquo;ê³¼ &lsquo;ë¶„ì‚°&rsquo;ì…ë‹ˆë‹¤.
 â€‹
â€‹
â€‹
ğŸ¤”ê²°ë¡ ë¶€í„° ë§í•˜ìë©´ ì˜ˆì¸¡ê°’ë“¤ê³¼ ì •ë‹µì´ ëŒ€ì²´ë¡œ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆìœ¼ë©´ í¸í–¥ì´ ë†“ë‹¤ê³  ë§í•˜ê³ ,
ì˜ˆì¸¡ê°’ë“¤ì´ ì„œë¡œ ë©€ë¦¬ í©ì–´ì ¸ ìˆìœ¼ë©´ ë¶„ì‚°ì´ ë†’ë‹¤ê³  ë§í•©ë‹ˆë‹¤.
â€‹
â€‹
â€‹
ì•„ë˜ ê·¸ë¦¼ì„ ë³´ë©´ ì™¼ìª½ ìƒë‹¨ ê³¼ë…ì€
ì˜ˆì¸¡ê°’ë“¤ì´ ëŒ€ì²´ë¡œ ì •ë‹µ ê·¼ë°©ì—ì„œ ì™”ë‹¤ê°”ë‹¤ í•©ë‹ˆë‹¤. &gt; í¸í–¥ì´ ë‚®ìŠµë‹ˆë‹¤.
ì˜ˆì¸¡ê°’ë“¤ë¼ë¦¬ ì„œë¡œ ëª°ë ¤ ìˆìŠµë‹ˆë‹¤. &gt; ë¶„ì‚°ì´ ë‚®ìŠµë‹ˆë‹¤.]]></description>
</item><item>
    <title>Activation_Function</title>
    <link>https://colinder.github.io/activation_function/</link>
    <pubDate>Thu, 24 Jun 2021 15:04:29 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://colinder.github.io/activation_function/</guid>
    <description><![CDATA[â€‹
Activation Function(í™œì„±í™” í•¨ìˆ˜)  ì…ë ¥ ì‹ í˜¸ì˜ ì´í•©ì„ ì¶œë ¥ì‹ í˜¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì¼ë°˜ì ìœ¼ë¡œ Activation Functionì´ë¼ê³  í•©ë‹ˆë‹¤.
 â€‹
ì•„ì§ ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤. í•˜ì—¬ ì¸ê³µì‹ ê²½ë§ì— ë¹—ëŒ€ì–´ ì´í•´í•´ë³´ê² ìŠµë‹ˆë‹¤.
ì¸ê³µ ì‹ ê²½ë§ì€ ì¸ê°„ì˜ ì¤‘ì¶”ì‹ ê²½ê³„(ë‡Œ)ì†ì˜ ë‰´ëŸ°ë“¤ì´ ì •ë³´ë¥¼ ì „ë‹¬í•˜ê³  í•™ìŠµí•˜ì—¬ ê²°ê³¼ë¥¼ ë„ì¶œí•´ë‚´ëŠ” ê³¼ì •ì„ ëª¨ë°©í•œ í•™ìŠµì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
ì—¬ê¸°ì„œ ì˜ë¬¸ì ì´ ìƒê¹ë‹ˆë‹¤.
  ì˜ˆë¥¼ ë“¤ì–´ ì§€ë‚˜ê°€ë‹¤ ê·¤ì„ ë³´ì•˜ëŠ”ë° ë§›ì´ ìˆì„ì§€ ì—†ì„ì§€ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”? ì € ê·¤ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ ë´…ì‹œë‹¤.
  íƒ€ì›í˜•, ì´ìœ ë…¸ë€ìƒ‰, í‘¸ë¥´ë¥¸ ê¼­ì§€ ë¼ëŠ” ë°ì´í„°ë¥¼ ëˆˆìœ¼ë¡œ ë³´ê³  ë‡Œì†ì˜ ë‰´ëŸ°ë“¤ì´ ì´ ì •ë³´ë¥¼ ë¶„ì„í•´ ë§›ìˆê² ë‹¤.]]></description>
</item><item>
    <title>Collaborative filtering by auto Encoder</title>
    <link>https://colinder.github.io/collaborative_filtering_by_autoencoder/</link>
    <pubDate>Wed, 16 Jun 2021 15:02:22 &#43;0900</pubDate>
    <author>Author</author>
    <guid>https://colinder.github.io/collaborative_filtering_by_autoencoder/</guid>
    <description><![CDATA[â€‹
Collaborative filtering by auto Encoder  í˜‘ì—…í•„í„°ë§ì„ ë”¥ëŸ¬ë‹ ë°©ì‹ì˜ í•˜ë‚˜ì¸ ì˜¤í†  ì¸ì½”ë”ë¡œ êµ¬í˜„í•˜ëŠ”ë° ì•Œì•„ë‘ì–´ì•¼ í•  ë°°ê²½ì§€ì‹ì— ëŒ€í•˜ì—¬ ì •ë¦¬
 â€‹
Machine learning   ê¸°ê³„ê°€ ëª…ì‹œì ìœ¼ë¡œ ì½”ë”©ë˜ì§€ ì•Šì€ ë™ì‘ì„ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•´ ìˆ˜í–‰í•˜ê²Œ í•˜ëŠ” ì—°êµ¬ ë¶„ì•¼. ì¸ê³µì§€ëŠ¥(AI)ì˜ í•œ ë¶„ì•¼ë¡œ ê°„ì£¼ëœë‹¤. ê¸°ê³„ í•™ìŠµì˜ í•µì‹¬ì€ í‘œí˜„(representation)ê³¼ ì¼ë°˜í™”(generalization)ì— ìˆë‹¤. í‘œí˜„ì´ë€ ë°ì´í„°ì˜ í‰ê°€ì´ë©°, ì¼ë°˜í™”ë€ ì•„ì§ ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„°ì— ëŒ€í•œ ì²˜ë¦¬ì´ë‹¤.
â€‹
  What&rsquo;s the difference with &lsquo;Deep learning&rsquo;?   Machine learningì€ ì–´ë–¤ ë¬¸ì œì™€ ë‹µì„ ë§‰ ë˜ì ¸ì£¼ë©´ ê¸°ê³„ê°€ ê³„ì† í’€ì–´ë‚´ë©´ì„œ ì¶”ìƒì ì¸ ì›ë¦¬ë¥¼ ìŠ¤ìŠ¤ë¡œ ê¹¨ìš°ì¹˜ê³  ìƒˆë¡œìš´ ë¬¸ì œê°€ ì£¼ì–´ì ¸ë„ ìŠ¤ìŠ¤ë¡œ ë‹µì„ ë‚¼ ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒì´ë‹¤.]]></description>
</item></channel>
</rss>
